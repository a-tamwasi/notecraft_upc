import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:http/http.dart' as http;
import 'package:http_parser/http_parser.dart';
import '../repositories/audio_transcription_repository.dart';

/// Classe d'exception personnalis√©e pour les erreurs li√©es √† l'API Deepgram.
class DeepgramException implements Exception {
  final String message;
  DeepgramException(this.message);

  @override
  String toString() => 'DeepgramException: $message';
}

/// Service optimis√© pour la transcription audio avec l'API Deepgram.
/// Utilise l'API REST de Deepgram pour transcrire des fichiers audio.
/// 
/// Avantages vs OpenAI:
/// - Pas de limite de 25MB pour les fichiers audio
/// - Transcription plus rapide 
/// - D√©tection automatique de TOUTES les langues
/// - Support de formats audio plus larges
/// - Smart formatting multilingue
/// 
/// TODO: √âcrire des tests unitaires pour DeepgramService
/// - Test de transcription avec fichier audio valide
/// - Test de gestion d'erreurs (cl√© API invalide, r√©seau indisponible)
/// - Test de gestion des timeouts
/// - Test avec diff√©rents formats audio (m4a, mp3, wav, webm)
/// - Mock du client HTTP pour tests isol√©s
class DeepgramService implements AudioTranscriptionRepository {
  /// L'endpoint de l'API Deepgram pour les transcriptions.
  static const String _transcriptionUrl = 'https://api.deepgram.com/v1/listen';
  
  /// Client HTTP r√©utilisable avec timeout optimis√© pour les longs audios
  static final http.Client _client = http.Client();

  /// R√©cup√®re la cl√© API Deepgram depuis les variables d'environnement de mani√®re s√©curis√©e.
  String _getApiKey() {
    final apiKey = dotenv.env['DEEPGRAM_API_KEY'];
    if (apiKey == null || apiKey.isEmpty || apiKey == 'VOTRE_CLE_DEEPGRAM_ICI') {
      throw DeepgramException(
        'Cl√© API Deepgram non trouv√©e. '
        'Assurez-vous d\'avoir cr√©√© un fichier .env √† la racine '
        'et d\'y avoir ajout√© votre cl√© : DEEPGRAM_API_KEY=VOTRE_CLE',
      );
    }
    return apiKey;
  }

  /// V√©rifie la taille du fichier audio avant envoi
  Future<File> _checkAudioFile(String filePath) async {
    final file = File(filePath);
    
    if (!await file.exists()) {
      throw DeepgramException('Le fichier audio n\'existe pas: $filePath');
    }
    
    final fileSize = await file.length();
    final extension = filePath.toLowerCase().split('.').last;
    
    print('üìÅ Taille du fichier: ${(fileSize / 1024 / 1024).toStringAsFixed(2)} MB');
    print('üìÑ Extension d√©tect√©e: .$extension');
    print('üéµ Type MIME: ${_getContentType(filePath)?.toString() ?? 'auto-d√©tect√©'}');
    
    // V√©rifier que le fichier n'est pas vide
    if (fileSize == 0) {
      throw DeepgramException('Le fichier audio est vide (0 bytes)');
    }
    
    // V√©rifier les formats support√©s par Deepgram
    const supportedFormats = ['m4a', 'mp3', 'wav', 'webm', 'ogg', 'flac', 'mp4', 'aac', 'aiff', 'au', 'dss', 'gsm', 'opus', 'raw', 'sphere', 'vox', 'wma'];
    if (!supportedFormats.contains(extension)) {
      print('‚ö†Ô∏è Format .$extension pas officiellement support√©, tentative quand m√™me...');
    } else {
      print('‚úÖ Format .$extension support√© par Deepgram');
    }
    
    print('‚úÖ Fichier valid√© pour Deepgram');
    return file;
  }

  /// Transcrit un fichier audio en utilisant l'API REST Deepgram avec optimisations de vitesse.
  Future<String> transcribeAudio(String filePath) async {
    // Utilisation du mod√®le "nova-2" qui est plus fiable pour les transcriptions compl√®tes
    // et ajout de param√®tres pour s'assurer d'avoir le texte complet
    // Documentation: https://developers.deepgram.com/docs/pre-recorded-audio
    return await _transcribeWithConfig(filePath, {
      'model': 'nova-2',           // Mod√®le plus fiable que whisper-large
      'detect_language': 'true',
      'smart_format': 'true',
      'punctuate': 'true',
      'filler_words': 'false',     // √âviter la perte de contenu
      'utterances': 'false',       // Simplifier pour √©viter les coupures
      'paragraphs': 'true',        // Garder pour un bon formatage
      'diarize': 'false',          // √âviter la complexit√© non n√©cessaire
    });
  }

  /// Transcrit un fichier audio avec des param√®tres optimis√©s pour la vitesse MAXIMALE
  /// Utilise les param√®tres les plus rapides possibles, au d√©triment de certaines fonctionnalit√©s
  Future<String> transcribeAudioFast(String filePath) async {
    return await _transcribeWithConfig(filePath, {
      'model': 'nova-2',           // Mod√®le le plus rapide
      'language': 'fr',            // Langue fixe au lieu de d√©tection auto (plus rapide)
      'punctuate': 'false',        // D√©sactiver la ponctuation pour plus de vitesse
      'filler_words': 'false',     // Pas de mots de remplissage
      'utterances': 'false',       // Pas de m√©tadonn√©es
      'paragraphs': 'false',       // Pas de formatage avanc√©
      'diarize': 'false',          // Pas de s√©paration des locuteurs
      'smart_format': 'false',     // Pas de formatage intelligent
      'profanity_filter': 'false', // Pas de filtre de grossi√®ret√©s
    });
  }

  /// M√©thode interne pour transcrire avec une configuration sp√©cifique
  Future<String> _transcribeWithConfig(String filePath, Map<String, String> queryParams) async {
    final stopwatch = Stopwatch()..start();
    
    try {
      print('üöÄ D√©but de la transcription Deepgram...');
      
      final apiKey = _getApiKey();
      final audioFile = await _checkAudioFile(filePath);
      final uri = Uri.parse(_transcriptionUrl).replace(queryParameters: queryParams);
      
      print('üîó URL Deepgram: ${uri.toString()}');
      print('üìã Configuration: ${queryParams.toString()}');

      // Cr√©ation d'une requ√™te standard, PAS multipart
      final request = http.Request('POST', uri);

      // D√©finition des headers
      request.headers.addAll({
        'Authorization': 'Token $apiKey',
        'User-Agent': 'NoteCraft/1.0 Flutter/Deepgram',
        'Accept': 'application/json',
        'Content-Type': _getContentType(filePath)?.toString() ?? 'application/octet-stream',
      });

      // Ajout du corps de la requ√™te avec les bytes du fichier
      print('üì§ Lecture et envoi des bytes du fichier...');
      request.bodyBytes = await audioFile.readAsBytes();
      print('üìä Bytes lus et pr√™ts √† envoyer: ${request.bodyBytes.length}');
      
      // Envoi de la requ√™te avec timeout √©tendu pour les longs audios
      print('‚è≥ Envoi √† Deepgram avec timeout de 5 minutes...');
      final streamedResponse = await _client.send(request).timeout(
        const Duration(minutes: 9), // Timeout g√©n√©reux pour les longs audios
        onTimeout: () {
          throw DeepgramException('Timeout de transcription (5 minutes). L\'audio est peut-√™tre trop long.');
        },
      );
      
      print('üì• R√©ception de la r√©ponse de Deepgram...');
      final response = await http.Response.fromStream(streamedResponse).timeout(
        const Duration(minutes: 2), // Timeout pour la lecture de la r√©ponse
        onTimeout: () {
          throw DeepgramException('Timeout lors de la lecture de la r√©ponse Deepgram.');
        },
      );

      stopwatch.stop();
      print('‚ö° Temps total Deepgram: ${stopwatch.elapsedMilliseconds}ms');

      // Traitement de la r√©ponse
      if (response.statusCode == 200) {
        final responseData = json.decode(response.body);
        
        final results = responseData['results'] as Map<String, dynamic>?;
        final channels = results?['channels'] as List<dynamic>?;
        if (channels == null || channels.isEmpty) {
          throw DeepgramException('R√©ponse invalide: structure de canaux manquante');
        }
        
        final firstChannel = channels[0] as Map<String, dynamic>;
        final alternatives = firstChannel['alternatives'] as List<dynamic>?;
        if (alternatives == null || alternatives.isEmpty) {
          throw DeepgramException('R√©ponse invalide: pas d\'alternatives de transcription');
        }
        
        final firstAlternative = alternatives[0] as Map<String, dynamic>;

        // Diagnostiquer la qualit√© de la r√©ponse Deepgram
        print('üîç DIAGNOSTIC DEEPGRAM:');
        print('   - Channels disponibles: ${channels.length}');
        print('   - Alternatives disponibles: ${alternatives.length}');
        
        // Analyser la structure compl√®te pour diagnostiquer les probl√®mes
        final metadata = results?['metadata'] as Map<String, dynamic>?;
        if (metadata != null) {
          final duration = metadata['duration'] as double?;
          final channels_meta = metadata['channels'] as int?;
          print('   - Dur√©e d√©tect√©e: ${duration?.toStringAsFixed(2)}s');
          print('   - Canaux audio: $channels_meta');
        }

        // Prioriser la transcription format√©e avec paragraphes pour un affichage propre
        final paragraphs = firstAlternative['paragraphs'] as Map<String, dynamic>?;
        if (paragraphs != null && paragraphs['transcript'] is String) {
          final formattedTranscript = paragraphs['transcript'] as String;
          if (formattedTranscript.trim().isNotEmpty) {
            print('‚úÖ Transcription avec paragraphes extraite (${formattedTranscript.length} caract√®res)');
            print('üéØ Premiers 100 caract√®res: "${formattedTranscript.substring(0, formattedTranscript.length < 100 ? formattedTranscript.length : 100)}..."');
            print('üéØ Derniers 100 caract√®res: "...${formattedTranscript.substring(formattedTranscript.length < 100 ? 0 : formattedTranscript.length - 100)}"');
            return formattedTranscript.trim();
          }
        }

        // Fallback sur la transcription simple si les paragraphes ne sont pas disponibles
        final transcription = firstAlternative['transcript'] as String?;
        if (transcription != null && transcription.trim().isNotEmpty) {
          print('‚úÖ Transcription simple extraite (${transcription.length} caract√®res)');
          print('üéØ Premiers 100 caract√®res: "${transcription.substring(0, transcription.length < 100 ? transcription.length : 100)}..."');
          print('üéØ Derniers 100 caract√®res: "...${transcription.substring(transcription.length < 100 ? 0 : transcription.length - 100)}"');
          return transcription.trim();
        }

        print('‚ö†Ô∏è Transcription vide re√ßue de Deepgram');
        print('üîç Structure de la r√©ponse: ${firstAlternative.keys.toList()}');
        return 'Aucun contenu audio d√©tect√©.';
        
      } else {
        // Gestion des erreurs Deepgram
        String errorMessage = 'Erreur Deepgram inconnue';
        try {
          final responseData = json.decode(response.body);
          errorMessage = responseData['err_msg'] ?? responseData['message'] ?? errorMessage;
        } catch (e) {
          errorMessage = 'Erreur HTTP ${response.statusCode}: ${response.reasonPhrase}';
        }
        throw DeepgramException('Erreur API Deepgram (${response.statusCode}): $errorMessage');
      }
      
    } on SocketException {
      throw DeepgramException('Erreur r√©seau. V√©rifiez votre connexion internet.');
    } catch (e) {
      stopwatch.stop();
      print('‚ùå Erreur Deepgram apr√®s ${stopwatch.elapsedMilliseconds}ms: $e');
      
      if (e is DeepgramException) {
        rethrow;
      }
      throw DeepgramException('Erreur inattendue: $e');
    }
  }

  /// D√©termine l'encodage audio selon l'extension du fichier
  String _getAudioEncoding(String filePath) {
    final extension = filePath.toLowerCase().split('.').last;
    switch (extension) {
      case 'm4a':
      case 'mp4':
        return 'mp4';
      case 'mp3':
        return 'mp3';
      case 'wav':
        return 'wav';
      case 'webm':
        return 'webm';
      case 'ogg':
        return 'ogg';
      case 'flac':
        return 'flac';
      default:
        return 'auto'; // Laisser Deepgram d√©tecter automatiquement
    }
  }

  /// D√©termine le type MIME optimal selon l'extension
  MediaType? _getContentType(String filePath) {
    final extension = filePath.toLowerCase().split('.').last;
    switch (extension) {
      case 'm4a':
      case 'mp4':
        return MediaType.parse('audio/mp4');
      case 'mp3':
        return MediaType.parse('audio/mpeg');
      case 'wav':
        return MediaType.parse('audio/wav');
      case 'webm':
        return MediaType.parse('audio/webm');
      case 'ogg':
        return MediaType.parse('audio/ogg');
      case 'flac':
        return MediaType.parse('audio/flac');
      case 'aac':
        return MediaType.parse('audio/aac');
      case 'aiff':
      case 'aif':
        return MediaType.parse('audio/aiff');
      case 'opus':
        return MediaType.parse('audio/opus');
      case 'wma':
        return MediaType.parse('audio/x-ms-wma');
      case 'au':
        return MediaType.parse('audio/basic');
      default:
        // Pour les formats non reconnus, utiliser application/octet-stream
        // Deepgram peut souvent d√©tecter automatiquement le format
        return MediaType.parse('application/octet-stream');
    }
  }

  /// Lib√®re les ressources
  void dispose() {
    // Les ressources statiques sont partag√©es, ne pas fermer ici
    // La fermeture se fait via closeHttpClient()
  }

  /// Nettoie les ressources HTTP statiques
  static void closeHttpClient() {
    _client.close();
  }
} 